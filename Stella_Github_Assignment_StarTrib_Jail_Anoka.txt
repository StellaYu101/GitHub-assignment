The repository I cloned is a Star Tribune python scraper program over the jail roster in Anoka County in Minnesota. (https://github.com/striblab/20170202-jail_roster_anoka) The link to the original data is no longer available.
It seems to me that the program scrapes raw data from the website and then convert it into a csv file. It then assigns a timestamp for each of the corresponding records using json, and it standardizes the format of the date and time. I don't have access to the original file, so I would guess that the timestamp is either for the date and time when the inmate was jailed, or for the time when the data is extracted. I couldn't fully understand the code, so I think this would be a question for the programmer if I were to replicate the codes in the future.
After assigning timestamps to the data, the program rewrites the original text file to include the timestamps as well. 
The next lines of codes seemed a bit more confusing. I don't quite understand the for loop. It seems to me that if an inmate's name doesn't pop up in the roster, the system jots down the key assigned to the record; if the inmate appears in the system once or more times, then the system recods the value.
The program then compares the roster to a list of names to check for hits. The last lines of codes lay out the format to record the records that are a hit.
I selected this repository because it's a python program that I hope to utilize in the future. This seems like a useful and simple scraper to allow comparison between two databases. There are some methods in this scraper program I still need to understand, but I hope I didn't get the gist of this program wrong. I'm curious about the json and sys libraries that the programmer imported, and how that is generally applied in a python program.